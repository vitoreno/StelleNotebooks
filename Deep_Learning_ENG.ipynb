{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Learning_ENG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBJqt6CRN35Y"
      },
      "source": [
        "# 1. Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9ccQ06-N8Rf"
      },
      "source": [
        "## 1.1 Preparing the notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJgz9HnOOASj"
      },
      "source": [
        "Press *play* in the following cell to import the datasets from the GitHub repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_hmu8meOFww"
      },
      "source": [
        "! git clone https://github.com/vitoreno/StelleDataset.git\n",
        "! unzip /content/StelleDataset/data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pOKbaEvOIMR"
      },
      "source": [
        "Press *play* in the following cell to import the libraries needed to run the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTbNUSXsOMYP"
      },
      "source": [
        "%load_ext google.colab.data_table\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vatXQWmuOuJN"
      },
      "source": [
        "## 1.2 Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bufLl61CO3Nz"
      },
      "source": [
        "We intend to predict the soil moisture values on the coast starting from the sea temperatures in the nearest points, through a neural network.\n",
        "\n",
        "The architecture of the network is very simple. It is made of two hidden layers with dimensions of 8 and 16 neurons. The network is trained with batch size 100 for 5 epochs.\n",
        "\n",
        "Select the regions to be trained on, and those to be evaluated on a given date. Possible dates range from 2016-01-01 to 2016-12-31. \n",
        "\n",
        "Finally press *play* to start the cell execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "aqLXd2P9OybP"
      },
      "source": [
        "#@markdown Training\n",
        "train_Adriatic = True #@param {type:\"boolean\"}\n",
        "train_Ionian = True #@param {type:\"boolean\"}\n",
        "train_Tyrrhenian = False #@param {type:\"boolean\"}\n",
        "train_Labrador = False #@param {type:\"boolean\"}\n",
        "train_Red = False #@param {type:\"boolean\"}\n",
        "#@markdown Test\n",
        "date_str = '2016-07-01' #@param {type:\"date\"}\n",
        "test_Adriatic = False #@param {type:\"boolean\"}\n",
        "test_Ionian = False #@param {type:\"boolean\"}\n",
        "test_Tyrrhenian = True #@param {type:\"boolean\"}\n",
        "test_Labrador = False #@param {type:\"boolean\"}\n",
        "test_Red = False #@param {type:\"boolean\"}\n",
        "\n",
        "train_list = []\n",
        "test_list = []\n",
        "if train_Adriatic:\n",
        "  train_list = train_list + [\"Adriatic\"]\n",
        "if train_Ionian:\n",
        "  train_list = train_list + [\"Ionian\"]\n",
        "if train_Tyrrhenian:\n",
        "  train_list = train_list + [\"Tyrrhenian\"]\n",
        "if train_Labrador:\n",
        "  train_list = train_list + [\"Labrador\"]\n",
        "if test_Red:\n",
        "  test_list = test_list + [\"Red\"]\n",
        "if test_Adriatic:\n",
        "  test_list = test_list + [\"Adriatic\"]\n",
        "if test_Ionian:\n",
        "  test_list = test_list + [\"Ionian\"]\n",
        "if test_Tyrrhenian:\n",
        "  test_list = test_list + [\"Tyrrhenian\"]\n",
        "if test_Labrador:\n",
        "  test_list = test_list + [\"Labrador\"]\n",
        "if test_Red:\n",
        "  test_list = test_list + [\"Red\"]\n",
        "\n",
        "current_date = datetime.strptime(date_str + \" 12:00:00\", '%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "if (current_date < datetime.strptime(\"2016-01-01 12:00:00\", '%Y-%m-%d %H:%M:%S')) | (current_date > datetime.strptime(\"2016-12-31 12:00:00\", '%Y-%m-%d %H:%M:%S')):\n",
        "  sys.exit(\"Data non valida. Inserire data compresa fra 2016-01-01 e 2016-12-31\")\n",
        "\n",
        "data = pd.read_csv(\"/content/soil_moisture_2016.csv\")\n",
        "data.time = pd.to_datetime(data.time)\n",
        "train_data = data.loc[data['sea'].isin(train_list)]\n",
        "test_data = data.loc[((data['sea'].isin(test_list)) & (data['time'] == current_date))]\n",
        "\n",
        "train_sst = train_data.sst.to_numpy().reshape(-1, 1)\n",
        "train_sm = train_data.sm.to_numpy()\n",
        "test_sst = test_data.sst.to_numpy().reshape(-1, 1)\n",
        "test_sm = test_data.sm.to_numpy()\n",
        "\n",
        "# Feature scaling\n",
        "sc = StandardScaler()\n",
        "train_sst = sc.fit_transform(train_sst)\n",
        "test_sst = sc.transform(test_sst)\n",
        "\n",
        "# Model\n",
        "model = Sequential()\n",
        "model.add(Dense(8, activation = 'relu', input_dim = 1))\n",
        "model.add(Dense(units = 16, activation = 'relu'))\n",
        "model.add(Dense(units = 1))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "# Training\n",
        "model.fit(train_sst, train_sm, batch_size = 100, epochs = 5)\n",
        "\n",
        "prediction = model.predict(test_sst).reshape(-1)\n",
        "\n",
        "for i in range(test_sm.shape[0]):\n",
        "  plt.plot([test_sst[i],test_sst[i]], [test_sm[i],prediction[i]], '--b')\n",
        "plt.scatter(test_sst, test_sm, color='black', label='Observation')\n",
        "plt.scatter(test_sst, prediction, color='blue', label='Prediction')\n",
        "plt.xlabel('Temperature')\n",
        "plt.ylabel('Albedo')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "results = pd.DataFrame({\"Observed albedo\": test_sm, \"Predicted albedo\": prediction, \"Error\": np.abs(test_sm - prediction)})\n",
        "print(\"Mean Squared Error: \", mean_squared_error(test_sm, prediction))\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}